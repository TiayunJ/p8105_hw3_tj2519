---
title: "p8105_hw3_tj2519"
output: github_document
date: "2023-10-09"
---

# Problem 1
## part1: load the library and dataset
```{r}
library(tidyverse)
library(ggridges)
library(p8105.datasets)
data("instacart")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## part2: calculate the number of aisles and number of items in each aisle
```{r}
problem1_df = instacart 
problem1_df %>% 
  group_by(aisle_id) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))

view(problem1_df)
```

## part3: make a plot showing the number of items ordered in each aisle
```{r}
problem1_df %>% 
  group_by(aisle_id) %>% 
  summarize(number_item = n()) %>% 
  filter(number_item > 10000) %>% 
  ggplot(aes(x = reorder(aisle_id, -number_item), y = number_item)) +
  geom_bar(stat = "identity", width = 0.5) + 
  theme(axis.text.x = element_text(size = 6)) +
  xlab("aisle_id") 
```

## part4: make a table

```{r}
problem1_df %>% 
  group_by(aisle, product_name) %>% 
  filter(aisle == "baking ingredients" |
           aisle == "dog food care" |
           aisle == "packaged vegetables fruits"
           ) %>% 
  summarize(order_num = n()) %>% 
  arrange(aisle, desc(order_num)) %>% 
  slice(1:3) %>% 
  pivot_wider(names_from = aisle,
              values_from = order_num)

```

## part5: make a new table
```{r}
problem1_df %>% 
  filter(product_name == "Pink Lady Apples" | 
           product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_order_time = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  pivot_wider(names_from = order_dow,
              values_from = mean_order_time)

```



# Problem 2
## part1: load the library and dataset
```{r}
library(p8105.datasets)
data("brfss_smart2010") 

view(brfss_smart2010)
```

## part2: cleaning the data
```{r}
problem2_df = brfss_smart2010

problem2_clean = problem2_df %>% 
  janitor::clean_names() %>% 
  rename(location_abbr = locationabbr, location_desc_order = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  drop_na(response) %>% 
  mutate(response = forcats::fct_relevel(
    response, c("Poor", "Fair", "Good", "Very good", "Excellent")))

```

## part3: answer the first question
```{r}
problem2_clean %>%
  filter(year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc_order)) %>% 
  filter(n_location >= 7)

problem2_clean %>%
  filter(year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(geo_location)) %>% 
  filter(n_location >= 7)

  
problem2_clean %>%
  filter(year == 2010) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc_order)) %>% 
  filter(n_location >= 7)
```
According to the results, in 2002, there are 6 states were observed at 7 or more locations (counties), and the 6 states are "CT, FL, MA, NC, NJ, PA". 









