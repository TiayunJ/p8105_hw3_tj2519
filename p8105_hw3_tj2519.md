p8105_hw3_tj2519
================
2023-10-09

# Problem 1

## part1: load the library and dataset

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(ggridges)
library(ggplot2)
library(p8105.datasets)
data("instacart")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## part2: calculate the number of aisles and number of items in each aisle

``` r
problem1_df = instacart 
problem1_df %>% 
  group_by(aisle_id) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

    ## # A tibble: 134 × 2
    ##    aisle_id  n_obs
    ##       <int>  <int>
    ##  1       83 150609
    ##  2       24 150473
    ##  3      123  78493
    ##  4      120  55240
    ##  5       21  41699
    ##  6      115  36617
    ##  7       84  32644
    ##  8      107  31269
    ##  9       91  26240
    ## 10      112  23635
    ## # ℹ 124 more rows

``` r
view(problem1_df)
```

## part3: make a plot showing the number of items ordered in each aisle

``` r
problem1_df %>% 
  group_by(aisle_id) %>% 
  summarize(number_item = n()) %>% 
  filter(number_item > 10000) %>% 
  ggplot(aes(x = reorder(aisle_id, -number_item), y = number_item)) +
  geom_bar(stat = "identity", width = 0.5) + 
  theme(axis.text.x = element_text(size = 6)) +
  xlab("aisle_id") 
```

<img src="p8105_hw3_tj2519_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

## part4: make a table

``` r
problem1_df %>% 
  group_by(aisle, product_name) %>% 
  filter(aisle == "baking ingredients" |
           aisle == "dog food care" |
           aisle == "packaged vegetables fruits"
           ) %>% 
  summarize(order_num = n()) %>% 
  arrange(aisle, desc(order_num)) %>% 
  slice(1:3) %>% 
  pivot_wider(names_from = aisle,
              values_from = order_num)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 9 × 4
    ##   product_name       `baking ingredients` `dog food care` packaged vegetables …¹
    ##   <chr>                             <int>           <int>                  <int>
    ## 1 Light Brown Sugar                   499              NA                     NA
    ## 2 Pure Baking Soda                    387              NA                     NA
    ## 3 Cane Sugar                          336              NA                     NA
    ## 4 Snack Sticks Chic…                   NA              30                     NA
    ## 5 Organix Chicken &…                   NA              28                     NA
    ## 6 Small Dog Biscuits                   NA              26                     NA
    ## 7 Organic Baby Spin…                   NA              NA                   9784
    ## 8 Organic Raspberri…                   NA              NA                   5546
    ## 9 Organic Blueberri…                   NA              NA                   4966
    ## # ℹ abbreviated name: ¹​`packaged vegetables fruits`

## part5: make a new table

``` r
problem1_df %>% 
  filter(product_name == "Pink Lady Apples" | 
           product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_order_time = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  pivot_wider(names_from = order_dow,
              values_from = mean_order_time)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 2 × 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

# Problem 2

## part1: load the library and dataset

``` r
library(p8105.datasets)
data("brfss_smart2010") 

view(brfss_smart2010)
```

## part2: cleaning the data

``` r
problem2_df = brfss_smart2010

problem2_clean = problem2_df %>% 
  janitor::clean_names() %>% 
  rename(location_abbr = locationabbr, location_desc_order = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  drop_na(response) %>% 
  mutate(response = forcats::fct_relevel(
    response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

## part3: answer the first question

``` r
state_2002 = problem2_clean %>%
  filter(year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc_order)) %>% 
  filter(n_location >= 7)

problem2_clean %>%
  filter(year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(geo_location)) %>% 
  filter(n_location >= 7)
```

    ## # A tibble: 6 × 2
    ##   location_abbr n_location
    ##   <chr>              <int>
    ## 1 CT                     7
    ## 2 FL                     7
    ## 3 MA                     8
    ## 4 NC                     7
    ## 5 NJ                     8
    ## 6 PA                    10

``` r
state_2007 = problem2_clean %>%
  filter(year == 2010) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc_order)) %>% 
  filter(n_location >= 7)
```

According to the results, in 2002, 6 states were observed at 7 or more
locations (counties), and the 6 states are “CT, FL, MA, NC, NJ, PA”. In
2010, 14 states were observed at 7 or more locations (counties), and the
14 states are “CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA”.

## part4: answer the second question

``` r
problem2_clean %>% 
  filter(response == "Excellent") %>% 
  group_by(location_abbr, year) %>% 
  summarize(data_value_mean = mean(data_value, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = data_value_mean, group = location_abbr, 
             color = location_abbr)) +
  geom_line() +
  theme_minimal() + 
  labs(title = "The change in the mean of data_value for the 'Excellent' category",
       y = "Mean of data value")
```

    ## `summarise()` has grouped output by 'location_abbr'. You can override using the
    ## `.groups` argument.

<img src="p8105_hw3_tj2519_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />
To make this plot, I move the legend to the right of the plot so it
could be more clear.

## part5: answer the third question

``` r
problem2_clean %>% 
  filter(location_abbr == "NY", year == 2006 | year == 2010) %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .5) +
  facet_grid(. ~ year) +
  labs(title = "Data value distribution for the year 2006 and 2010 in New York",
       x= "Data value distribution")
```

<img src="p8105_hw3_tj2519_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

``` r
problem2_clean %>% 
  filter(location_abbr == "NY", year == 2006 | year == 2010) %>% 
  group_by(year) %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  labs(title = "Data value distribution for the year 2006 and 2010 in New York",
       x= "Data value distribution")
```

<img src="p8105_hw3_tj2519_files/figure-gfm/unnamed-chunk-10-2.png" width="90%" />
I firstly filter the datset to include only the data in NY and only the
observations from 2006 and 2010. Then, to show the distribution of each
response type, I draw a density plot. Then, we split the plot according
to the value of each year.

# Problem 3

## part1: read the two datasets and tidy the two datasets, also apply left_join by “seqn” to merge the two datasets

``` r
demo_data = 
  read_csv("data/nhanes_covar.csv", skip = 4) %>% 
  janitor::clean_names() %>% 
  filter(age >= 21) %>% 
  drop_na() %>% 
  mutate(sex = recode(sex, `2` = "female", `1` = "male"),
         education = recode(education, `1` = "Less than high school", 
                                      `2` = "High school equivalent",
                                      `3` = "More than high school"))
```

    ## Rows: 250 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (5): SEQN, sex, age, BMI, education
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
acc_data =
  read_csv("data/nhanes_accel.csv") %>% 
  janitor::clean_names()
```

    ## Rows: 250 Columns: 1441
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (1441): SEQN, min1, min2, min3, min4, min5, min6, min7, min8, min9, min1...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
demo_acc_join = 
  left_join(demo_data, acc_data, by = "seqn")


view(acc_data)
view(demo_data)
view(demo_acc_join)
```

## part2: encode data

``` r
demo_acc_join 
```

    ## # A tibble: 228 × 1,445
    ##     seqn sex      age   bmi education     min1   min2   min3  min4   min5   min6
    ##    <dbl> <chr>  <dbl> <dbl> <chr>        <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl>
    ##  1 62161 male      22  23.3 High school… 1.11  3.12   1.47   0.938 1.60   0.145 
    ##  2 62164 female    44  23.2 More than h… 1.92  1.67   2.38   0.935 2.59   5.22  
    ##  3 62169 male      21  20.1 High school… 5.85  5.18   4.76   6.48  6.85   7.24  
    ##  4 62174 male      80  33.9 More than h… 5.42  3.48   3.72   3.81  6.85   4.45  
    ##  5 62177 male      51  20.1 High school… 6.14  8.06   9.99   6.60  4.57   2.78  
    ##  6 62178 male      80  28.5 High school… 0.167 0.429  0.131  1.20  0.0796 0.0487
    ##  7 62180 male      35  27.9 More than h… 0.039 0      0      0     0.369  0.265 
    ##  8 62184 male      26  22.1 High school… 1.55  2.81   3.86   4.76  6.10   7.61  
    ##  9 62189 female    30  22.4 More than h… 2.81  0.195  0.163  0     0.144  0.180 
    ## 10 62199 male      57  28   More than h… 0.031 0.0359 0.0387 0.079 0.109  0.262 
    ## # ℹ 218 more rows
    ## # ℹ 1,434 more variables: min7 <dbl>, min8 <dbl>, min9 <dbl>, min10 <dbl>,
    ## #   min11 <dbl>, min12 <dbl>, min13 <dbl>, min14 <dbl>, min15 <dbl>,
    ## #   min16 <dbl>, min17 <dbl>, min18 <dbl>, min19 <dbl>, min20 <dbl>,
    ## #   min21 <dbl>, min22 <dbl>, min23 <dbl>, min24 <dbl>, min25 <dbl>,
    ## #   min26 <dbl>, min27 <dbl>, min28 <dbl>, min29 <dbl>, min30 <dbl>,
    ## #   min31 <dbl>, min32 <dbl>, min33 <dbl>, min34 <dbl>, min35 <dbl>, …
